{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"https://github.com/adixxov/Applied_AI_Course/blob/main/class02_representation/06_Training_embeddings_using_gensim.ipynb","timestamp":1726048062052}],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.13"},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"2WGPwjhbbwPT"},"source":["## Training Embeddings Using Gensim\n","Word embeddings are an approach to representing text in NLP. In this notebook we will demonstrate how to train embeddings using Genism. [Gensim](https://radimrehurek.com/gensim/index.html) is an open source Python library for natural language processing, with a focus on topic modeling (explained in chapter 7)."]},{"cell_type":"code","source":["!pip3 install virtualenv\n","!virtualenv ai_course_env"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BC2RxkewfS46","executionInfo":{"status":"ok","timestamp":1726048300864,"user_tz":240,"elapsed":19291,"user":{"displayName":"Ahmed Doha","userId":"12463812440394629153"}},"outputId":"1aba7bb7-e93e-49c8-f7f9-a1af39fb515b"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting virtualenv\n","  Downloading virtualenv-20.26.4-py3-none-any.whl.metadata (4.5 kB)\n","Collecting distlib<1,>=0.3.7 (from virtualenv)\n","  Downloading distlib-0.3.8-py2.py3-none-any.whl.metadata (5.1 kB)\n","Requirement already satisfied: filelock<4,>=3.12.2 in /usr/local/lib/python3.10/dist-packages (from virtualenv) (3.15.4)\n","Requirement already satisfied: platformdirs<5,>=3.9.1 in /usr/local/lib/python3.10/dist-packages (from virtualenv) (4.2.2)\n","Downloading virtualenv-20.26.4-py3-none-any.whl (6.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading distlib-0.3.8-py2.py3-none-any.whl (468 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.9/468.9 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: distlib, virtualenv\n","Successfully installed distlib-0.3.8 virtualenv-20.26.4\n","created virtual environment CPython3.10.12.final.0-64 in 1496ms\n","  creator CPython3Posix(dest=/content/ai_course_env, clear=False, no_vcs_ignore=False, global=False)\n","  seeder FromAppData(download=False, pip=bundle, setuptools=bundle, wheel=bundle, via=copy, app_data_dir=/root/.local/share/virtualenv)\n","    added seed packages: pip==24.2, setuptools==74.1.2, wheel==0.44.0\n","  activators BashActivator,CShellActivator,FishActivator,NushellActivator,PowerShellActivator,PythonActivator\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eyXXFeFZ750T","outputId":"687a6b6e-98ce-4433-ae00-8a5ef38446d4","executionInfo":{"status":"ok","timestamp":1726048374746,"user_tz":240,"elapsed":26901,"user":{"displayName":"Ahmed Doha","userId":"12463812440394629153"}}},"source":["!source /content/ai_course_env/bin/activate; pip install gensim==3.6.0\n","!source /content/ai_course_env/bin/activate; pip install requests==2.23.0"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting gensim==3.6.0\n","  Downloading gensim-3.6.0.tar.gz (23.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.1/23.1 MB\u001b[0m \u001b[31m139.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting numpy>=1.11.3 (from gensim==3.6.0)\n","  Using cached numpy-2.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n","Collecting scipy>=0.18.1 (from gensim==3.6.0)\n","  Downloading scipy-1.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n","Collecting six>=1.5.0 (from gensim==3.6.0)\n","  Using cached six-1.16.0-py2.py3-none-any.whl.metadata (1.8 kB)\n","Collecting smart_open>=1.2.1 (from gensim==3.6.0)\n","  Using cached smart_open-7.0.4-py3-none-any.whl.metadata (23 kB)\n","Collecting wrapt (from smart_open>=1.2.1->gensim==3.6.0)\n","  Using cached wrapt-1.16.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n","Using cached numpy-2.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.3 MB)\n","Downloading scipy-1.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (41.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.2/41.2 MB\u001b[0m \u001b[31m70.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hUsing cached six-1.16.0-py2.py3-none-any.whl (11 kB)\n","Using cached smart_open-7.0.4-py3-none-any.whl (61 kB)\n","Using cached wrapt-1.16.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (80 kB)\n","Building wheels for collected packages: gensim\n","  Building wheel for gensim (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gensim: filename=gensim-3.6.0-cp310-cp310-linux_x86_64.whl size=23483422 sha256=a02aa5ef92718f4e3c1da8efedd6ad2921743fc1aefce7d14bca8f18669fc76a\n","  Stored in directory: /root/.cache/pip/wheels/00/e8/47/96f55c3144a5ea3537f549f7a97607011f5004b9f13fa8dcc5\n","Successfully built gensim\n","Installing collected packages: wrapt, six, numpy, smart_open, scipy, gensim\n","Successfully installed gensim-3.6.0 numpy-2.1.1 scipy-1.14.1 six-1.16.0 smart_open-7.0.4 wrapt-1.16.0\n","Collecting requests==2.23.0\n","  Downloading requests-2.23.0-py2.py3-none-any.whl.metadata (6.8 kB)\n","Collecting chardet<4,>=3.0.2 (from requests==2.23.0)\n","  Downloading chardet-3.0.4-py2.py3-none-any.whl.metadata (3.2 kB)\n","Collecting idna<3,>=2.5 (from requests==2.23.0)\n","  Downloading idna-2.10-py2.py3-none-any.whl.metadata (9.1 kB)\n","Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 (from requests==2.23.0)\n","  Downloading urllib3-1.25.11-py2.py3-none-any.whl.metadata (41 kB)\n","Collecting certifi>=2017.4.17 (from requests==2.23.0)\n","  Using cached certifi-2024.8.30-py3-none-any.whl.metadata (2.2 kB)\n","Downloading requests-2.23.0-py2.py3-none-any.whl (58 kB)\n","Using cached certifi-2024.8.30-py3-none-any.whl (167 kB)\n","Downloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n","Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n","Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n","Installing collected packages: chardet, urllib3, idna, certifi, requests\n","Successfully installed certifi-2024.8.30 chardet-3.0.4 idna-2.10 requests-2.23.0 urllib3-1.25.11\n"]}]},{"cell_type":"code","metadata":{"id":"TBw9OCYcYQ_n","ExecuteTime":{"end_time":"2024-09-07T17:11:37.229390Z","start_time":"2024-09-07T17:11:35.481768Z"},"executionInfo":{"status":"ok","timestamp":1726048413523,"user_tz":240,"elapsed":1505,"user":{"displayName":"Ahmed Doha","userId":"12463812440394629153"}}},"source":["from gensim.models import Word2Vec\n","import warnings\n","warnings.filterwarnings('ignore')"],"outputs":[],"execution_count":3},{"cell_type":"code","metadata":{"id":"5qWptd54ZcfV","ExecuteTime":{"end_time":"2024-09-07T17:11:39.711414Z","start_time":"2024-09-07T17:11:39.668664Z"},"executionInfo":{"status":"ok","timestamp":1726048434828,"user_tz":240,"elapsed":189,"user":{"displayName":"Ahmed Doha","userId":"12463812440394629153"}}},"source":["# define training data\n","#Genism word2vec requires that a format of ‘list of lists’ be provided for training where every document contained in a list.\n","#Every list contains lists of tokens of that document.\n","corpus = [['dog','bites','man'], [\"man\", \"bites\" ,\"dog\"],[\"dog\",\"eats\",\"meat\"],[\"man\", \"eats\",\"food\"]]\n","\n","#Training the model\n","model_cbow = Word2Vec(corpus, min_count=1,sg=0) #using CBOW Architecture for trainnig\n","model_skipgram = Word2Vec(corpus, min_count=1,sg=1)#using skipGram Architecture for training"],"outputs":[],"execution_count":4},{"cell_type":"code","source":["dir(model_cbow.wv)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PQMPR3vUg6Q7","executionInfo":{"status":"ok","timestamp":1726048644093,"user_tz":240,"elapsed":181,"user":{"displayName":"Ahmed Doha","userId":"12463812440394629153"}},"outputId":"22732606-08f8-454b-8729-f8f6374542eb"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['__class__',\n"," '__contains__',\n"," '__delattr__',\n"," '__dict__',\n"," '__dir__',\n"," '__doc__',\n"," '__eq__',\n"," '__format__',\n"," '__ge__',\n"," '__getattribute__',\n"," '__getitem__',\n"," '__gt__',\n"," '__hash__',\n"," '__init__',\n"," '__init_subclass__',\n"," '__le__',\n"," '__len__',\n"," '__lt__',\n"," '__module__',\n"," '__ne__',\n"," '__new__',\n"," '__reduce__',\n"," '__reduce_ex__',\n"," '__repr__',\n"," '__setattr__',\n"," '__setitem__',\n"," '__sizeof__',\n"," '__str__',\n"," '__subclasshook__',\n"," '__weakref__',\n"," '_adapt_by_suffix',\n"," '_load_specials',\n"," '_log_evaluate_word_analogies',\n"," '_save_specials',\n"," '_smart_save',\n"," '_upconvert_old_d2vkv',\n"," '_upconvert_old_vocab',\n"," 'add_lifecycle_event',\n"," 'add_vector',\n"," 'add_vectors',\n"," 'allocate_vecattrs',\n"," 'closer_than',\n"," 'cosine_similarities',\n"," 'distance',\n"," 'distances',\n"," 'doesnt_match',\n"," 'evaluate_word_analogies',\n"," 'evaluate_word_pairs',\n"," 'expandos',\n"," 'fill_norms',\n"," 'get_index',\n"," 'get_mean_vector',\n"," 'get_normed_vectors',\n"," 'get_vecattr',\n"," 'get_vector',\n"," 'has_index_for',\n"," 'index2entity',\n"," 'index2word',\n"," 'index_to_key',\n"," 'init_sims',\n"," 'intersect_word2vec_format',\n"," 'key_to_index',\n"," 'load',\n"," 'load_word2vec_format',\n"," 'log_accuracy',\n"," 'log_evaluate_word_pairs',\n"," 'mapfile_path',\n"," 'most_similar',\n"," 'most_similar_cosmul',\n"," 'most_similar_to_given',\n"," 'n_similarity',\n"," 'next_index',\n"," 'norms',\n"," 'rank',\n"," 'rank_by_centrality',\n"," 'relative_cosine_similarity',\n"," 'resize_vectors',\n"," 'save',\n"," 'save_word2vec_format',\n"," 'set_vecattr',\n"," 'similar_by_key',\n"," 'similar_by_vector',\n"," 'similar_by_word',\n"," 'similarity',\n"," 'similarity_unseen_docs',\n"," 'sort_by_descending_frequency',\n"," 'unit_normalize_all',\n"," 'vector_size',\n"," 'vectors',\n"," 'vectors_for_all',\n"," 'vectors_lockf',\n"," 'vectors_norm',\n"," 'vocab',\n"," 'wmdistance',\n"," 'word_vec',\n"," 'words_closer_than']"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["type(model_cbow.wv.get_vector)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9obBDlTwiJg2","executionInfo":{"status":"ok","timestamp":1726049038399,"user_tz":240,"elapsed":162,"user":{"displayName":"Ahmed Doha","userId":"12463812440394629153"}},"outputId":"7df13f40-c005-4e03-a7ba-487f06ddbd7f"},"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["method"]},"metadata":{},"execution_count":21}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nyZY8ME4lUjd","outputId":"a99240b7-7c56-432e-da95-13392ed3e3af","ExecuteTime":{"end_time":"2024-09-07T17:12:16.287637Z","start_time":"2024-09-07T17:12:16.277073Z"},"executionInfo":{"status":"ok","timestamp":1726049055757,"user_tz":240,"elapsed":173,"user":{"displayName":"Ahmed Doha","userId":"12463812440394629153"}}},"source":["#Summarize the loaded model\n","print(model_cbow)\n","\n","#Summarize vocabulary\n","words = list(model_cbow.wv.key_to_index)\n","print(words)\n","\n","#Acess vector for one word\n","print(model_cbow.wv.get_vector('dog'))"],"outputs":[{"output_type":"stream","name":"stdout","text":["Word2Vec<vocab=6, vector_size=100, alpha=0.025>\n","['man', 'dog', 'eats', 'bites', 'food', 'meat']\n","[-8.6196875e-03  3.6657380e-03  5.1898835e-03  5.7419385e-03\n","  7.4669183e-03 -6.1676754e-03  1.1056137e-03  6.0472824e-03\n"," -2.8400505e-03 -6.1735227e-03 -4.1022300e-04 -8.3689485e-03\n"," -5.6000124e-03  7.1045388e-03  3.3525396e-03  7.2256695e-03\n","  6.8002474e-03  7.5307419e-03 -3.7891543e-03 -5.6180597e-04\n","  2.3483764e-03 -4.5190323e-03  8.3887316e-03 -9.8581640e-03\n","  6.7646410e-03  2.9144168e-03 -4.9328315e-03  4.3981876e-03\n"," -1.7395747e-03  6.7113843e-03  9.9648498e-03 -4.3624435e-03\n"," -5.9933780e-04 -5.6956373e-03  3.8508223e-03  2.7866268e-03\n","  6.8910765e-03  6.1010956e-03  9.5384968e-03  9.2734173e-03\n","  7.8980681e-03 -6.9895042e-03 -9.1558648e-03 -3.5575271e-04\n"," -3.0998408e-03  7.8943167e-03  5.9385742e-03 -1.5456629e-03\n","  1.5109634e-03  1.7900408e-03  7.8175711e-03 -9.5101865e-03\n"," -2.0553112e-04  3.4691966e-03 -9.3897223e-04  8.3817719e-03\n","  9.0107834e-03  6.5365066e-03 -7.1162102e-04  7.7104042e-03\n"," -8.5343346e-03  3.2071066e-03 -4.6379971e-03 -5.0889552e-03\n","  3.5896183e-03  5.3703394e-03  7.7695143e-03 -5.7665063e-03\n","  7.4333609e-03  6.6254963e-03 -3.7098003e-03 -8.7456414e-03\n","  5.4374672e-03  6.5097557e-03 -7.8755023e-04 -6.7098560e-03\n"," -7.0859254e-03 -2.4970602e-03  5.1432536e-03 -3.6652375e-03\n"," -9.3700597e-03  3.8267397e-03  4.8844791e-03 -6.4285635e-03\n","  1.2085581e-03 -2.0748770e-03  2.4403334e-05 -9.8835090e-03\n","  2.6920044e-03 -4.7501065e-03  1.0876465e-03 -1.5762246e-03\n","  2.1966731e-03 -7.8815762e-03 -2.7171839e-03  2.6631986e-03\n","  5.3466819e-03 -2.3915148e-03 -9.5100943e-03  4.5058788e-03]\n"]}],"execution_count":22},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gMuHv52GeuoR","outputId":"fc913355-39d5-45f5-cce6-0bdf32dd41d0","ExecuteTime":{"end_time":"2024-09-07T17:13:18.872194Z","start_time":"2024-09-07T17:13:18.861141Z"},"executionInfo":{"status":"ok","timestamp":1726049117716,"user_tz":240,"elapsed":199,"user":{"displayName":"Ahmed Doha","userId":"12463812440394629153"}}},"source":["#Compute similarity\n","print(\"Similarity between eats and bites:\",model_cbow.wv.similarity('eats', 'bites'))\n","print(\"Similarity between eats and man:\",model_cbow.wv.similarity('eats', 'man'))"],"outputs":[{"output_type":"stream","name":"stdout","text":["Similarity between eats and bites: -0.0134970825\n","Similarity between eats and man: -0.05235437\n"]}],"execution_count":24},{"cell_type":"markdown","metadata":{"id":"twhTZfPOezTU"},"source":["From the above similarity scores we can conclude that eats is more similar to bites than man."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5Lv0V7WofmsB","outputId":"d25b6b27-1d2b-49ca-dc81-458345055331","ExecuteTime":{"end_time":"2024-09-07T17:13:32.073760Z","start_time":"2024-09-07T17:13:32.065310Z"},"executionInfo":{"status":"ok","timestamp":1726049245298,"user_tz":240,"elapsed":178,"user":{"displayName":"Ahmed Doha","userId":"12463812440394629153"}}},"source":["#Most similarity\n","model_cbow.wv.most_similar('meat')"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('food', 0.13887985050678253),\n"," ('bites', 0.13149003684520721),\n"," ('eats', 0.06422408670186996),\n"," ('dog', 0.009391166269779205),\n"," ('man', -0.05987630784511566)]"]},"metadata":{},"execution_count":25}],"execution_count":25},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2021-04-05T21:26:59.855822Z","start_time":"2021-04-05T21:26:59.841810Z"},"colab":{"base_uri":"https://localhost:8080/"},"id":"WA783nrSalgs","outputId":"5c38c595-d4d3-4564-f416-088ab80f6e45"},"source":["# save model\n","model_cbow.save('model_cbow.bin')\n","\n","# load model\n","new_model_cbow = Word2Vec.load('model_cbow.bin')\n","print(new_model_cbow)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Word2Vec(vocab=6, size=100, alpha=0.025)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"deReLSI7mQyr"},"source":["## SkipGram\n","In skipgram, the task is to predict the context words from the center word."]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2021-04-05T21:27:00.517046Z","start_time":"2021-04-05T21:27:00.508038Z"},"colab":{"base_uri":"https://localhost:8080/"},"id":"9QtUtsLglvY0","outputId":"e9108e9c-c727-42e1-a574-3cd26a64f730"},"source":["#Summarize the loaded model\n","print(model_skipgram)\n","\n","#Summarize vocabulary\n","words = list(model_skipgram.wv.vocab)\n","print(words)\n","\n","#Acess vector for one word\n","print(model_skipgram['dog'])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Word2Vec(vocab=6, size=100, alpha=0.025)\n","['dog', 'bites', 'man', 'eats', 'meat', 'food']\n","[ 2.5211656e-03 -4.7110780e-03  2.8306653e-03  1.2988835e-03\n"," -2.8097455e-03  3.5701145e-03 -1.0838461e-03 -2.7250070e-03\n"," -8.1295683e-04  1.5667123e-03  2.4118358e-03 -4.7246739e-03\n","  4.0631713e-03 -2.5763465e-03 -1.6118506e-04 -1.7885152e-03\n"," -4.3171244e-03 -2.2182211e-03 -7.9603918e-04 -2.0051922e-03\n"," -4.0520830e-03  3.5601703e-03 -4.8916014e-03  8.3168899e-04\n","  1.8691848e-03 -7.2068983e-04  1.7822703e-03  4.8909439e-03\n","  1.4495224e-04  7.1767234e-04  4.7240019e-04 -4.7488464e-03\n","  3.2012935e-03 -2.2545501e-03  5.5779086e-04 -8.5462094e-04\n"," -2.0693108e-03 -3.2387851e-03 -4.7898539e-03  2.9532199e-03\n"," -2.6267513e-03  4.3456843e-03 -3.6019234e-03 -3.1687848e-03\n"," -4.4510062e-03  3.2532150e-03 -5.6775135e-04  4.9478044e-03\n","  3.7174521e-03 -1.2643889e-03  4.7942945e-03  4.2697912e-04\n","  3.9527160e-03  1.0574544e-06 -4.1726064e-03 -4.9871374e-03\n","  4.4140723e-03 -3.0756535e-03 -6.5692631e-04  1.4224187e-03\n"," -3.3482790e-03 -7.5503299e-04  2.6607935e-03  4.2536319e-04\n"," -2.6803287e-03 -2.8118992e-04  4.6384442e-03 -1.1165573e-03\n"," -7.5188163e-04  8.7776553e-04 -2.2422627e-03 -3.6135935e-03\n"," -1.5384768e-03  1.3317144e-03 -1.4385344e-03  2.2318382e-03\n"," -2.6432027e-03 -2.7398622e-04 -1.9744197e-03 -2.2871925e-03\n","  5.5917882e-04 -6.1914866e-04 -7.2595594e-04  4.9666516e-03\n"," -2.7891367e-03  5.4704654e-04 -3.7604810e-03  1.7327523e-03\n","  1.5019998e-03 -1.9850212e-03 -2.5780164e-03  1.5672717e-03\n","  4.8756734e-03 -3.2661748e-03  1.0153219e-03  1.7714992e-03\n","  1.8529573e-03 -4.1100634e-03  4.3286928e-03 -1.6125903e-03]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2021-04-05T21:27:02.660747Z","start_time":"2021-04-05T21:27:02.642866Z"},"colab":{"base_uri":"https://localhost:8080/"},"id":"8YUsblEOfFWf","outputId":"26a66cd2-3d89-4c7b-ef1b-a7f3df4e248e"},"source":["#Compute similarity\n","print(\"Similarity between eats and bites:\",model_skipgram.similarity('eats', 'bites'))\n","print(\"Similarity between eats and man:\",model_skipgram.similarity('eats', 'man'))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Similarity between eats and bites: -0.17754517\n","Similarity between eats and man: 0.15367937\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"gdXVDePKnBpv"},"source":["From the above similarity scores we can conclude that eats is more similar to bites than man."]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2021-04-05T21:27:03.419546Z","start_time":"2021-04-05T21:27:03.414541Z"},"colab":{"base_uri":"https://localhost:8080/"},"id":"lpF4qtwpmuM3","outputId":"a90d8d36-5fef-44f2-d0ad-6abce255ed11"},"source":["#Most similarity\n","model_skipgram.most_similar('meat')"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('bites', 0.0787399411201477),\n"," ('dog', 0.07166968286037445),\n"," ('food', 0.01594177447259426),\n"," ('man', -0.060993026942014694),\n"," ('eats', -0.12379160523414612)]"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2021-04-05T21:27:03.973454Z","start_time":"2021-04-05T21:27:03.950433Z"},"colab":{"base_uri":"https://localhost:8080/"},"id":"aNDCEXRTnAnj","outputId":"1109d578-1e2c-4311-8e04-35e58568aa56"},"source":["# save model\n","model_skipgram.save('model_skipgram.bin')\n","\n","# load model\n","new_model_skipgram = Word2Vec.load('model_skipgram.bin')\n","print(new_model_skipgram)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Word2Vec(vocab=6, size=100, alpha=0.025)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"b0MiqJ_1M0mX"},"source":["## Training Your Embedding on Wiki Corpus\n","\n","##### The corpus download page : https://dumps.wikimedia.org/enwiki/20200120/\n","The entire wiki corpus as of 28/04/2020 is just over 16GB in size.\n","We will take a part of this corpus due to computation constraints and train our word2vec and fasttext embeddings.\n","\n","The file size is 294MB so it can take a while to download.\n","\n","Source for code which downloads files from Google Drive: https://stackoverflow.com/questions/25010369/wget-curl-large-file-from-google-drive/39225039#39225039"]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2021-04-05T21:27:58.596845Z","start_time":"2021-04-05T21:27:58.585833Z"},"colab":{"base_uri":"https://localhost:8080/"},"id":"cLq8kxmF750d","outputId":"1b71df74-bbcf-4ff9-8e8a-5723eb68519f"},"source":["import os\n","import requests\n","\n","os.makedirs('data/en', exist_ok= True)\n","file_name = \"data/en/enwiki-latest-pages-articles-multistream14.xml-p13159683p14324602.bz2\"\n","file_id = \"11804g0GcWnBIVDahjo5fQyc05nQLXGwF\"\n","\n","def download_file_from_google_drive(id, destination):\n","    URL = \"https://docs.google.com/uc?export=download\"\n","\n","    session = requests.Session()\n","\n","    response = session.get(URL, params = { 'id' : id }, stream = True)\n","    token = get_confirm_token(response)\n","\n","    if token:\n","        params = { 'id' : id, 'confirm' : token }\n","        response = session.get(URL, params = params, stream = True)\n","\n","    save_response_content(response, destination)\n","\n","def get_confirm_token(response):\n","    for key, value in response.cookies.items():\n","        if key.startswith('download_warning'):\n","            return value\n","\n","    return None\n","\n","def save_response_content(response, destination):\n","    CHUNK_SIZE = 32768\n","\n","    with open(destination, \"wb\") as f:\n","        for chunk in response.iter_content(CHUNK_SIZE):\n","            if chunk: # filter out keep-alive new chunks\n","                f.write(chunk)\n","\n","if not os.path.exists(file_name):\n","    download_file_from_google_drive(file_id, file_name)\n","else:\n","    print(\"file already exists, skipping download\")\n","\n","print(f\"File at: {file_name}\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["File at: data/en/enwiki-latest-pages-articles-multistream14.xml-p13159683p14324602.bz2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2021-04-03T08:59:17.024306Z","start_time":"2021-04-03T08:59:17.022304Z"},"id":"wX1kx96JLYvt"},"source":["from gensim.corpora.wikicorpus import WikiCorpus\n","from gensim.models.word2vec import Word2Vec\n","from gensim.models.fasttext import FastText\n","import time"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2021-04-03T09:56:14.722195Z","start_time":"2021-04-03T09:56:14.705177Z"},"id":"rJgsEUmRPppc"},"source":["#Preparing the Training data\n","wiki = WikiCorpus(file_name, lemmatize=False, dictionary={})\n","sentences = list(wiki.get_texts())\n","\n","#if you get a memory error executing the lines above\n","#comment the lines out and uncomment the lines below.\n","#loading will be slower, but stable.\n","# wiki = WikiCorpus(file_name, processes=4, lemmatize=False, dictionary={})\n","# sentences = list(wiki.get_texts())\n","\n","#if you still get a memory error, try settings processes to 1 or 2 and then run it again."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xsIrgt_gPQda"},"source":["### Hyperparameters\n","\n","\n","1.   sg - Selecting the training algorithm: 1 for skip-gram else its 0 for CBOW. Default is CBOW.\n","2.   min_count-  Ignores all words with total frequency lower than this.<br>\n","There are many more hyperparamaeters whose list can be found in the official documentation [here.](https://radimrehurek.com/gensim/models/word2vec.html)\n"]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2021-04-03T10:01:20.065332Z","start_time":"2021-04-03T09:59:12.350872Z"},"colab":{"base_uri":"https://localhost:8080/"},"id":"idmfbr_8LvoN","outputId":"197ec8aa-7849-4775-8f91-7ce0d365045d"},"source":["#CBOW\n","start = time.time()\n","word2vec_cbow = Word2Vec(sentences,min_count=10, sg=0)\n","end = time.time()\n","\n","print(\"CBOW Model Training Complete.\\nTime taken for training is:{:.2f} hrs \".format((end-start)/3600.0))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["CBOW Model Training Complete.\n","Time taken for training is:0.07 hrs \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2021-04-03T10:02:10.613551Z","start_time":"2021-04-03T10:02:10.585535Z"},"colab":{"base_uri":"https://localhost:8080/"},"id":"mMdGn08-RkhM","outputId":"f0072a3f-f82d-422f-e9a0-91952d3a6d49"},"source":["#Summarize the loaded model\n","print(word2vec_cbow)\n","print(\"-\"*30)\n","\n","#Summarize vocabulary\n","words = list(word2vec_cbow.wv.vocab)\n","print(f\"Length of vocabulary: {len(words)}\")\n","print(\"Printing the first 30 words.\")\n","print(words[:30])\n","print(\"-\"*30)\n","\n","#Acess vector for one word\n","print(f\"Length of vector: {len(word2vec_cbow['film'])}\")\n","print(word2vec_cbow['film'])\n","print(\"-\"*30)\n","\n","#Compute similarity\n","print(\"Similarity between film and drama:\",word2vec_cbow.similarity('film', 'drama'))\n","print(\"Similarity between film and tiger:\",word2vec_cbow.similarity('film', 'tiger'))\n","print(\"-\"*30)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Word2Vec(vocab=111150, size=100, alpha=0.025)\n","------------------------------\n","Length of vocabulary: 111150\n","Printing the first 30 words.\n","['the', 'roses', 'registered', 'as', 'is', 'brisbane', 'racing', 'club', 'group', 'thoroughbred', 'horse', 'race', 'for', 'three', 'year', 'old', 'filles', 'run', 'under', 'set', 'weights', 'conditions', 'over', 'distance', 'of', 'metres', 'at', 'racecourse', 'australia', 'during']\n","------------------------------\n","Length of vector: 100\n","[ 2.99669266e-01 -2.30107337e-01 -2.83332348e+00  1.79103506e+00\n"," -2.36173677e+00  1.72570646e+00  1.64380169e+00 -1.66164470e+00\n"," -3.12124300e+00  3.81150126e-01  1.35081375e+00 -2.21470922e-01\n","  1.52899250e-01  1.70926428e+00  1.81681314e-03 -9.03216541e-01\n"," -4.65534389e-01  2.37153435e+00  3.28944230e+00 -4.95558918e-01\n"," -5.94740689e-01 -1.57181859e+00  4.11749452e-01  1.24216557e+00\n"," -4.07071066e+00 -2.27307582e+00 -1.66209900e+00 -2.24222684e+00\n"," -1.05932796e+00  1.05019844e+00 -1.72928619e+00 -4.00999689e+00\n","  1.46719182e+00 -2.24276233e+00  1.24641347e+00 -4.21524572e+00\n","  9.76656258e-01  1.79963934e+00  1.48509622e+00 -4.56236362e-01\n"," -5.58120251e-01 -1.45934904e+00  2.32831573e+00  1.03190398e+00\n","  6.54682994e-01  2.95263624e+00 -8.23639572e-01 -4.16845202e-01\n","  1.64990544e+00 -8.86838377e-01 -2.78195834e+00 -5.65565884e-01\n"," -9.37131822e-01 -1.84206712e+00 -2.54025197e+00 -2.59079266e+00\n","  3.04947972e+00  2.50614357e+00 -1.34396338e+00 -1.10412195e-01\n","  1.44633248e-01  1.49436712e+00 -2.54006624e+00  8.65549624e-01\n","  2.23652887e+00  1.53001559e+00  2.01494312e+00  3.58992107e-02\n","  6.22256696e-01  1.00823784e+00 -1.38142657e+00 -2.27997160e+00\n"," -3.88184333e+00 -1.71323574e+00  2.19179511e+00 -1.16301203e+00\n","  2.01094699e+00  2.23023248e+00 -2.47916889e+00 -2.68365979e+00\n","  1.86766863e+00  1.41087270e+00  1.65393925e+00  1.78987586e+00\n"," -3.02522612e+00 -7.62253821e-01  1.23129368e+00 -2.54643726e+00\n","  1.98462141e+00  4.09366941e+00 -5.82411528e-01 -6.60197318e-01\n","  1.68045485e+00 -2.45697308e+00 -3.63437384e-01  1.38892472e+00\n","  6.35629117e-01 -1.44658887e+00  1.53073406e+00 -1.64472818e+00]\n","------------------------------\n","Similarity between film and drama: 0.49768686\n","Similarity between film and tiger: 0.17885588\n","------------------------------\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2021-04-03T10:02:16.109851Z","start_time":"2021-04-03T10:02:15.257052Z"},"id":"rXrDOrKskcHX"},"source":["# save model\n","from gensim.models import Word2Vec, KeyedVectors\n","word2vec_cbow.wv.save_word2vec_format('word2vec_cbow.bin', binary=True)\n","\n","# load model\n","# new_modelword2vec_cbow = Word2Vec.load('word2vec_cbow.bin')\n","# print(word2vec_cbow)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2021-04-03T10:08:27.736688Z","start_time":"2021-04-03T10:02:19.197708Z"},"colab":{"base_uri":"https://localhost:8080/"},"id":"dX0U0CbQOK30","outputId":"a86c4a77-0c9f-464b-d283-9808fa434b72"},"source":["#SkipGram\n","start = time.time()\n","word2vec_skipgram = Word2Vec(sentences,min_count=10, sg=1)\n","end = time.time()\n","\n","print(\"SkipGram Model Training Complete\\nTime taken for training is:{:.2f} hrs \".format((end-start)/3600.0))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["SkipGram Model Training Complete\n","Time taken for training is:0.20 hrs \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2021-04-03T10:09:06.406929Z","start_time":"2021-04-03T10:09:06.383908Z"},"colab":{"base_uri":"https://localhost:8080/"},"id":"LXnY9YInSvnI","outputId":"b151eb0c-2870-4df2-d38f-2cc4613d2f7b"},"source":["#Summarize the loaded model\n","print(word2vec_skipgram)\n","print(\"-\"*30)\n","\n","#Summarize vocabulary\n","words = list(word2vec_skipgram.wv.vocab)\n","print(f\"Length of vocabulary: {len(words)}\")\n","print(\"Printing the first 30 words.\")\n","print(words[:30])\n","print(\"-\"*30)\n","\n","#Acess vector for one word\n","print(f\"Length of vector: {len(word2vec_skipgram['film'])}\")\n","print(word2vec_skipgram['film'])\n","print(\"-\"*30)\n","\n","#Compute similarity\n","print(\"Similarity between film and drama:\",word2vec_skipgram.similarity('film', 'drama'))\n","print(\"Similarity between film and tiger:\",word2vec_skipgram.similarity('film', 'tiger'))\n","print(\"-\"*30)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Word2Vec(vocab=111150, size=100, alpha=0.025)\n","------------------------------\n","Length of vocabulary: 111150\n","Printing the first 30 words.\n","['the', 'roses', 'registered', 'as', 'is', 'brisbane', 'racing', 'club', 'group', 'thoroughbred', 'horse', 'race', 'for', 'three', 'year', 'old', 'filles', 'run', 'under', 'set', 'weights', 'conditions', 'over', 'distance', 'of', 'metres', 'at', 'racecourse', 'australia', 'during']\n","------------------------------\n","Length of vector: 100\n","[-0.4237168  -0.27985552 -0.25927952  0.3400125  -0.6667841   0.5012484\n"," -0.05727514  0.04838533  0.29251036 -0.4952073  -0.11132739 -0.06375849\n"," -0.10024641 -0.42574143  0.41230604  0.24994987 -0.1766596   0.2103304\n"," -0.36034128 -0.07717225  0.3511364  -0.3076286  -0.3552336  -0.15659297\n"," -0.1312314  -0.05537846  0.02508126 -0.66197944  0.02561701 -0.49367282\n","  0.36917788 -0.5463784  -0.01422684 -0.03367303 -0.1291493  -0.07956319\n"," -0.6713077   0.46974298  0.02238307 -0.29419112 -0.18262397  0.01855985\n","  0.37098563  0.15520486  0.6158194   0.14578134 -0.0547451  -0.08172174\n","  0.6428707   0.69385684 -0.44253206  0.22313416 -0.602879    0.28839922\n","  0.12988937 -0.07168498  0.10405575  0.0210879   0.0764401   0.52331465\n"," -0.09891954  0.83509344  0.24751136  0.7138662   0.22889751 -0.0279275\n"," -0.16131927 -0.16907     0.62423456  0.07625601 -0.6266109   0.07464166\n"," -0.647908    0.01609853  0.615516   -0.37575197  0.18886834  0.47542006\n"," -0.32108703  0.11722455  0.07091893 -0.18740237 -0.0066558  -0.3284618\n"," -0.40218323  0.18022484 -0.12150235  0.12267566  0.04140777  0.32418764\n"," -0.46062672  0.16411439  0.14221986 -0.36627144 -0.39216483 -0.12107299\n"," -0.34011865  0.17285857  0.29473382  0.24891974]\n","------------------------------\n","Similarity between film and drama: 0.6375442\n","Similarity between film and tiger: 0.27470022\n","------------------------------\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2021-04-03T10:09:09.947695Z","start_time":"2021-04-03T10:09:09.076901Z"},"id":"o8U7bfPSVB04"},"source":["# save model\n","word2vec_skipgram.wv.save_word2vec_format('word2vec_sg.bin', binary=True)\n","\n","# load model\n","# new_model_skipgram = Word2Vec.load('model_skipgram.bin')\n","# print(model_skipgram)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kExlA8kfrKml"},"source":["## FastText"]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2021-04-03T10:16:31.271764Z","start_time":"2021-04-03T10:09:16.592670Z"},"colab":{"base_uri":"https://localhost:8080/"},"id":"JPd2VhMEk8gL","outputId":"e4ed35b2-4338-4341-e150-68763015d3af"},"source":["#CBOW\n","start = time.time()\n","fasttext_cbow = FastText(sentences, sg=0, min_count=10)\n","end = time.time()\n","\n","print(\"FastText CBOW Model Training Complete\\nTime taken for training is:{:.2f} hrs \".format((end-start)/3600.0))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["FastText CBOW Model Training Complete\n","Time taken for training is:0.23 hrs \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2021-04-03T10:16:31.287283Z","start_time":"2021-04-03T10:16:31.273765Z"},"colab":{"base_uri":"https://localhost:8080/"},"id":"FlQFl8-Zsost","outputId":"49e9cf5f-58c2-4cb6-89e1-c70eb0686c37"},"source":["#Summarize the loaded model\n","print(fasttext_cbow)\n","print(\"-\"*30)\n","\n","#Summarize vocabulary\n","words = list(fasttext_cbow.wv.vocab)\n","print(f\"Length of vocabulary: {len(words)}\")\n","print(\"Printing the first 30 words.\")\n","print(words[:30])\n","print(\"-\"*30)\n","\n","#Acess vector for one word\n","print(f\"Length of vector: {len(fasttext_cbow['film'])}\")\n","print(fasttext_cbow['film'])\n","print(\"-\"*30)\n","\n","#Compute similarity\n","print(\"Similarity between film and drama:\",fasttext_cbow.similarity('film', 'drama'))\n","print(\"Similarity between film and tiger:\",fasttext_cbow.similarity('film', 'tiger'))\n","print(\"-\"*30)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["FastText(vocab=111150, size=100, alpha=0.025)\n","------------------------------\n","Length of vocabulary: 111150\n","Printing the first 30 words.\n","['the', 'roses', 'registered', 'as', 'is', 'brisbane', 'racing', 'club', 'group', 'thoroughbred', 'horse', 'race', 'for', 'three', 'year', 'old', 'filles', 'run', 'under', 'set', 'weights', 'conditions', 'over', 'distance', 'of', 'metres', 'at', 'racecourse', 'australia', 'during']\n","------------------------------\n","Length of vector: 100\n","[-0.7463835   0.19996189 -0.9979853   4.532985    0.9235125   2.189045\n"," -0.31808636  3.3484747   2.8904202   5.01124     0.67354566 -5.330121\n","  1.8081079  -0.06147059 -2.9210417   0.6564837   6.27072    -2.7427194\n","  3.8220415  -2.6083946  -0.57947993  1.2608125   3.7221222   3.707661\n"," -1.8702508  -2.0417852  -2.6469572  -1.7629712  -6.2687297  -0.79994273\n"," -2.7692544  -0.12231357 -0.887583    1.3647972  -0.46990368  2.2163184\n","  1.366861    4.930337   -3.1075075  -1.6002316   3.0699844   1.11122\n"," -6.8713775   1.8483716   0.41645643 -0.31872118  3.0096054  -5.532156\n","  1.6102395   3.6963217   3.663656   -6.4579606  -3.445696    1.0995266\n"," -0.17502166 -3.2351615  -1.7987081   0.7715877  -6.5901     -4.052606\n","  0.5506413   1.1240537  -0.9817307  -0.31660768  0.8579029  -4.9299016\n"," -0.46215907  0.5550937  -1.6686828  -3.7654505  -1.6888901  -3.583499\n","  0.53538233  1.8650341   1.4992528  -2.3350844  -0.72052157  0.29675376\n","  0.83089775  4.7392993   3.6813757  -4.458476   -1.6399952   1.5136546\n","  6.0058446  -3.4515505  -1.1562546  -1.0320979   4.9725256  -2.6820443\n","  2.3510482   0.08649306 -1.3958253  -1.3848797   2.1836684  -0.8967892\n"," -1.0972841  -1.391695   -0.34907514  2.9456055 ]\n","------------------------------\n","Similarity between film and drama: 0.5775347\n","Similarity between film and tiger: 0.23721316\n","------------------------------\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2021-04-03T10:28:28.771383Z","start_time":"2021-04-03T10:16:31.289284Z"},"colab":{"base_uri":"https://localhost:8080/"},"id":"UgSOxsNklAvh","outputId":"07242007-88e5-47c2-dbb7-7378e91c045c"},"source":["#SkipGram\n","start = time.time()\n","fasttext_skipgram = FastText(sentences, sg=1, min_count=10)\n","end = time.time()\n","\n","print(\"FastText SkipGram Model Training Complete\\nTime taken for training is:{:.2f} hrs \".format((end-start)/3600.0))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["FastText SkipGram Model Training Complete\n","Time taken for training is:0.34 hrs \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2021-04-03T10:28:28.803412Z","start_time":"2021-04-03T10:28:28.773386Z"},"colab":{"base_uri":"https://localhost:8080/"},"id":"vFiTAP0PsQwi","outputId":"a376e4ff-bf30-4af8-e192-979ab2a09622"},"source":["#Summarize the loaded model\n","print(fasttext_skipgram)\n","print(\"-\"*30)\n","\n","#Summarize vocabulary\n","words = list(fasttext_skipgram.wv.vocab)\n","print(f\"Length of vocabulary: {len(words)}\")\n","print(\"Printing the first 30 words.\")\n","print(words[:30])\n","print(\"-\"*30)\n","\n","#Acess vector for one word\n","print(f\"Length of vector: {len(fasttext_skipgram['film'])}\")\n","print(fasttext_skipgram['film'])\n","print(\"-\"*30)\n","\n","#Compute similarity\n","print(\"Similarity between film and drama:\",fasttext_skipgram.similarity('film', 'drama'))\n","print(\"Similarity between film and tiger:\",fasttext_skipgram.similarity('film', 'tiger'))\n","print(\"-\"*30)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["FastText(vocab=111150, size=100, alpha=0.025)\n","------------------------------\n","Length of vocabulary: 111150\n","Printing the first 30 words.\n","['the', 'roses', 'registered', 'as', 'is', 'brisbane', 'racing', 'club', 'group', 'thoroughbred', 'horse', 'race', 'for', 'three', 'year', 'old', 'filles', 'run', 'under', 'set', 'weights', 'conditions', 'over', 'distance', 'of', 'metres', 'at', 'racecourse', 'australia', 'during']\n","------------------------------\n","Length of vector: 100\n","[-0.34062257  0.20034881 -0.32438838  0.4757775   0.09694169  0.44387358\n","  0.374473    0.07984764  0.12626715  0.14559336  0.17070621 -0.1242009\n"," -0.02354645  0.2784064   0.01321098  0.10675827  0.5270286   0.18560082\n","  0.1947721  -0.09488335 -0.70429     0.03798589  0.36020663  0.4540548\n","  0.82588804 -0.03594406 -0.7010492   0.08276882 -0.3600402  -0.09103949\n"," -0.20812891 -0.0266632   0.18376034 -0.03438908  0.18739544 -0.54230857\n","  0.11515257 -0.76714796 -0.38413116  0.20995826  0.26379701 -0.14478317\n"," -0.2507331  -0.23866925 -0.08976771 -0.04520001  0.29641178 -0.01864165\n"," -0.3423282   0.13574615 -0.51550657  0.06460916 -0.20277704  0.63167423\n","  0.11858363 -0.37470454  0.16942851 -0.2089076  -0.02568607 -0.34627503\n","  0.2632271   0.22352041 -0.7899547   0.64767504  0.13887273 -0.38190958\n"," -0.18631777 -0.18322898 -0.31751177 -0.08308626  0.06825356  0.5401109\n","  0.03384253  0.30849797  0.1353884  -0.00637501 -0.25858733 -0.10995787\n"," -0.36130926 -0.26093003 -0.18051757 -0.9410778  -0.3630112  -0.21754144\n","  0.40985683 -0.07011902 -0.13193497 -0.04322884 -0.01041945  0.57367086\n"," -0.01106291 -0.02348732  0.84524894 -0.02717869 -0.0918304   0.43145362\n"," -0.17965347  0.39955035 -0.25133947 -0.20945397]\n","------------------------------\n","Similarity between film and drama: 0.64032143\n","Similarity between film and tiger: 0.3475386\n","------------------------------\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"oArMIJzYOmUR"},"source":["#### An interesting obeseravtion if you noticed is that CBOW trains faster than SkipGram in both cases.\n","We will leave it to the user to figure out why. A hint would be to refer the working of CBOW and skipgram."]}]}